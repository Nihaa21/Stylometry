{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stylometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expertai.nlapi.cloud.client import ExpertAiClient\n",
    "client = ExpertAiClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting expertai-nlapi\n",
      "  Downloading expertai_nlapi-2.5.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in ./opt/anaconda3/lib/python3.7/site-packages (from expertai-nlapi) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->expertai-nlapi) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->expertai-nlapi) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->expertai-nlapi) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->expertai-nlapi) (2019.11.28)\n",
      "Installing collected packages: expertai-nlapi\n",
      "Successfully installed expertai-nlapi-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install expertai-nlapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"EAI_USERNAME\"] = 'nihaghali554@gmail.com'\n",
    "os.environ[\"EAI_PASSWORD\"] = 'Daltadka@@21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"speeches/presidential_speeches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1789-04-30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>Washington calls on Congress to avoid local an...</td>\n",
       "      <td>Fellow Citizens of the Senate and the House of...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789-10-03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Thanksgiving Proclamation</td>\n",
       "      <td>At the request of Congress, Washington establi...</td>\n",
       "      <td>Whereas it is the duty of all Nations to ackno...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790-01-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Annual Message to Congress</td>\n",
       "      <td>In a wide ranging speech, President Washington...</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1790-12-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Second Annual Message to Congress</td>\n",
       "      <td>Washington focuses on commerce in his second a...</td>\n",
       "      <td>Fellow citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1790-12-29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Talk to the Chiefs and Counselors of the Senec...</td>\n",
       "      <td>The President reassures the Seneca Nation that...</td>\n",
       "      <td>I the President of the United States, by my ow...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          President         Party  \\\n",
       "0  1789-04-30  George Washington  Unaffiliated   \n",
       "1  1789-10-03  George Washington  Unaffiliated   \n",
       "2  1790-01-08  George Washington  Unaffiliated   \n",
       "3  1790-12-08  George Washington  Unaffiliated   \n",
       "4  1790-12-29  George Washington  Unaffiliated   \n",
       "\n",
       "                                        Speech Title  \\\n",
       "0                            First Inaugural Address   \n",
       "1                          Thanksgiving Proclamation   \n",
       "2                   First Annual Message to Congress   \n",
       "3                  Second Annual Message to Congress   \n",
       "4  Talk to the Chiefs and Counselors of the Senec...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Washington calls on Congress to avoid local an...   \n",
       "1  At the request of Congress, Washington establi...   \n",
       "2  In a wide ranging speech, President Washington...   \n",
       "3  Washington focuses on commerce in his second a...   \n",
       "4  The President reassures the Seneca Nation that...   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  Fellow Citizens of the Senate and the House of...   \n",
       "1  Whereas it is the duty of all Nations to ackno...   \n",
       "2  Fellow Citizens of the Senate and House of Rep...   \n",
       "3  Fellow citizens of the Senate and House of Rep...   \n",
       "4  I the President of the United States, by my ow...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://millercenter.org/the-presidency/presid...  \n",
       "1  https://millercenter.org/the-presidency/presid...  \n",
       "2  https://millercenter.org/the-presidency/presid...  \n",
       "3  https://millercenter.org/the-presidency/presid...  \n",
       "4  https://millercenter.org/the-presidency/presid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import nltk\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(full_text, chunk_size=9000):\n",
    "    tokenized_text= nltk.tokenize.sent_tokenize(full_text)\n",
    "    chunked_text=[]\n",
    "    while len(tokenized_text) >0:\n",
    "        character_sum=0\n",
    "        chunk=[]\n",
    "        counter=0\n",
    "        while character_sum <= chunk_size:\n",
    "            try:\n",
    "                chunk.append(tokenized_text[counter])\n",
    "                character_sum += len(tokenized_text[counter])\n",
    "                counter += 1\n",
    "            except IndexError:\n",
    "                break\n",
    "        chunked_text.append(\" \".join(chunk))\n",
    "        tokenized_text = tokenized_text[counter:]\n",
    "    return chunked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " random.seed(1138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('all')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_speeches = random.sample(\n",
    "    list(chain.from_iterable([chunker(speech) for speech in df[df.President==\"Barack Obama\"].Transcript.to_list()])),60)\n",
    "trump_speeches = random.sample(\n",
    "    list(chain.from_iterable([chunker(speech) for speech in df[df.President==\"Donald Trump\"].Transcript.to_list()])),60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_speeches = pd.DataFrame({\"text\": obama_speeches + trump_speeches, \"author\": [\"obama\"]*60 + [\"trump\"]*60 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding writeprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expertai.nlapi.cloud.client import ExpertAiClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_writeprint(string):\n",
    "    load_dotenv()\n",
    "    client = ExpertAiClient()\n",
    "    return client.detection(\n",
    "    body={\"document\": {\"text\": string}},\n",
    "    params={\"detector\": \"writeprint\",\"language\":\"en\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JSON-LD': {'@context': {'readabilityIndexes': 'https://schema.org/additionalProperty',\n",
       "   'name': 'https://schema.org/name',\n",
       "   'value': 'https://schema.org/value',\n",
       "   'total': 'https://schema.org/Number',\n",
       "   'readabilityLevel': 'https://schema.org/Text',\n",
       "   'structureIndexes': 'https://schema.org/Thing',\n",
       "   'mean': 'https://schema.org/Number',\n",
       "   'standardDeviation': 'https://schema.org/Number',\n",
       "   'meanAbsoluteDeviation': 'https://schema.org/Number',\n",
       "   'sentences': 'https://schema.org/QuantitativeValue',\n",
       "   'tokens': 'https://schema.org/QuantitativeValue',\n",
       "   'tokenLengthPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'verbTypes': 'https://schema.org/QuantitativeValue',\n",
       "   'charactersPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'atomsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'tokensPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'phrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'verbTypesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'capitalFirstLetterSentences': 'https://schema.org/QuantitativeValue',\n",
       "   'smallFirstLetterSentences': 'https://schema.org/QuantitativeValue',\n",
       "   'adjectivesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'adverbsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'articlesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'auxiliariesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'conjunctionsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'nounsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'properNounsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'punctuationPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'prepositionsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'pronounsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'particlesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'verbsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'namedEntitiesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'adjectivePhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'conjunctionPhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'adverbPhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'nounPhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'nominalPredicatesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'prepositionPhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'relativePhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'verbPhrasesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'unknownConceptsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'emoticonsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'academicLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'businessLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'crimeLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'laymanLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'legalLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'militaryLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'politicalLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'socialMediaLanguageWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'colonsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'commasPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'dotsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'doubleQuotationMarksPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'exclamationMarksPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'exclamationMarkQuestionMarkSequencesPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'multipleDotsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'multipleExclamationMarksPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'multipleQuestionMarksPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'questionMarksPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'semicolonsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'singleQuotationMarksPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'commonlyMisspelledWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'functionWordsPerSentence': 'https://schema.org/QuantitativeValue',\n",
       "   'mostCommonWordsPerSentence': 'https://schema.org/QuantitativeValue'},\n",
       "  '@graph': [{'@type': 'https://schema.org/Thing',\n",
       "    'readabilityIndexes': [{'@type': 'https://schema.org/PropertyValue',\n",
       "      'name': 'Coleman-Liau',\n",
       "      'value': 9.68,\n",
       "      'readabilityLevel': 'Difficult'},\n",
       "     {'@type': 'https://schema.org/PropertyValue',\n",
       "      'name': 'Gulpease',\n",
       "      'value': 55.75,\n",
       "      'readabilityLevel': 'Medium'},\n",
       "     {'@type': 'https://schema.org/PropertyValue',\n",
       "      'name': 'Automated Readability Index',\n",
       "      'value': 12.15,\n",
       "      'readabilityLevel': 'Very Difficult'}],\n",
       "    'structureIndexes': {'sentences': {'total': 67},\n",
       "     'tokens': {'total': 1709},\n",
       "     'tokenLengthPerSentence': {'mean': 4.37,\n",
       "      'standardDeviation': 3.22,\n",
       "      'meanAbsoluteDeviation': 2.48},\n",
       "     'verbTypes': {'total': 15},\n",
       "     'charactersPerSentence': {'mean': 136.47,\n",
       "      'standardDeviation': 70.11,\n",
       "      'meanAbsoluteDeviation': 55.72,\n",
       "      'total': 9144},\n",
       "     'atomsPerSentence': {'mean': 26.92,\n",
       "      'standardDeviation': 13.18,\n",
       "      'meanAbsoluteDeviation': 10.93,\n",
       "      'total': 1804},\n",
       "     'tokensPerSentence': {'mean': 25.5,\n",
       "      'standardDeviation': 12.4,\n",
       "      'meanAbsoluteDeviation': 10.23,\n",
       "      'total': 1709},\n",
       "     'phrasesPerSentence': {'mean': 15.73,\n",
       "      'standardDeviation': 7.85,\n",
       "      'meanAbsoluteDeviation': 6.47,\n",
       "      'total': 1054},\n",
       "     'verbTypesPerSentence': {'mean': 2.71,\n",
       "      'standardDeviation': 1.31,\n",
       "      'meanAbsoluteDeviation': 1.13,\n",
       "      'total': 15},\n",
       "     'smallFirstLetterSentences': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'capitalFirstLetterSentences': {'mean': 1,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 67},\n",
       "     'adjectivesPerSentence': {'mean': 2.55,\n",
       "      'standardDeviation': 2.01,\n",
       "      'meanAbsoluteDeviation': 1.49,\n",
       "      'total': 171},\n",
       "     'adverbsPerSentence': {'mean': 1,\n",
       "      'standardDeviation': 1.09,\n",
       "      'meanAbsoluteDeviation': 0.77,\n",
       "      'total': 67},\n",
       "     'articlesPerSentence': {'mean': 1.8,\n",
       "      'standardDeviation': 1.37,\n",
       "      'meanAbsoluteDeviation': 1.09,\n",
       "      'total': 121},\n",
       "     'auxiliariesPerSentence': {'mean': 1.1,\n",
       "      'standardDeviation': 0.88,\n",
       "      'meanAbsoluteDeviation': 0.63,\n",
       "      'total': 74},\n",
       "     'conjunctionsPerSentence': {'mean': 1.85,\n",
       "      'standardDeviation': 1.5,\n",
       "      'meanAbsoluteDeviation': 1.14,\n",
       "      'total': 124},\n",
       "     'nounsPerSentence': {'mean': 4.8,\n",
       "      'standardDeviation': 2.83,\n",
       "      'meanAbsoluteDeviation': 2.2,\n",
       "      'total': 322},\n",
       "     'properNounsPerSentence': {'mean': 0.73,\n",
       "      'standardDeviation': 1.22,\n",
       "      'meanAbsoluteDeviation': 0.89,\n",
       "      'total': 49},\n",
       "     'punctuationPerSentence': {'mean': 2.74,\n",
       "      'standardDeviation': 1.6,\n",
       "      'meanAbsoluteDeviation': 1.32,\n",
       "      'total': 184},\n",
       "     'prepositionsPerSentence': {'mean': 3.29,\n",
       "      'standardDeviation': 2.13,\n",
       "      'meanAbsoluteDeviation': 1.75,\n",
       "      'total': 221},\n",
       "     'pronounsPerSentence': {'mean': 2.23,\n",
       "      'standardDeviation': 1.59,\n",
       "      'meanAbsoluteDeviation': 1.19,\n",
       "      'total': 150},\n",
       "     'particlesPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'verbsPerSentence': {'mean': 3.37,\n",
       "      'standardDeviation': 1.93,\n",
       "      'meanAbsoluteDeviation': 1.62,\n",
       "      'total': 226},\n",
       "     'namedEntitiesPerSentence': {'mean': 0.74,\n",
       "      'standardDeviation': 1.25,\n",
       "      'meanAbsoluteDeviation': 0.91,\n",
       "      'total': 50},\n",
       "     'adjectivePhrasesPerSentence': {'mean': 0.13,\n",
       "      'standardDeviation': 0.41,\n",
       "      'meanAbsoluteDeviation': 0.24,\n",
       "      'total': 9},\n",
       "     'conjunctionPhrasesPerSentence': {'mean': 1.83,\n",
       "      'standardDeviation': 1.5,\n",
       "      'meanAbsoluteDeviation': 1.12,\n",
       "      'total': 123},\n",
       "     'adverbPhrasesPerSentence': {'mean': 0.41,\n",
       "      'standardDeviation': 0.77,\n",
       "      'meanAbsoluteDeviation': 0.58,\n",
       "      'total': 28},\n",
       "     'nounPhrasesPerSentence': {'mean': 3.97,\n",
       "      'standardDeviation': 2.34,\n",
       "      'meanAbsoluteDeviation': 1.81,\n",
       "      'total': 266},\n",
       "     'nominalPredicatesPerSentence': {'mean': 0.32,\n",
       "      'standardDeviation': 0.58,\n",
       "      'meanAbsoluteDeviation': 0.47,\n",
       "      'total': 22},\n",
       "     'prepositionPhrasesPerSentence': {'mean': 2.94,\n",
       "      'standardDeviation': 2.13,\n",
       "      'meanAbsoluteDeviation': 1.7,\n",
       "      'total': 197},\n",
       "     'relativePhrasesPerSentence': {'mean': 0.52,\n",
       "      'standardDeviation': 0.77,\n",
       "      'meanAbsoluteDeviation': 0.65,\n",
       "      'total': 35},\n",
       "     'verbPhrasesPerSentence': {'mean': 3.05,\n",
       "      'standardDeviation': 1.92,\n",
       "      'meanAbsoluteDeviation': 1.56,\n",
       "      'total': 205},\n",
       "     'unknownConceptsPerSentence': {'mean': 0.02,\n",
       "      'standardDeviation': 0.17,\n",
       "      'meanAbsoluteDeviation': 0.05,\n",
       "      'total': 2},\n",
       "     'emoticonsPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'academicLanguageWordsPerSentence': {'mean': 0.01,\n",
       "      'standardDeviation': 0.12,\n",
       "      'meanAbsoluteDeviation': 0.02,\n",
       "      'total': 1},\n",
       "     'businessLanguageWordsPerSentence': {'mean': 0.13,\n",
       "      'standardDeviation': 0.45,\n",
       "      'meanAbsoluteDeviation': 0.24,\n",
       "      'total': 9},\n",
       "     'crimeLanguageWordsPerSentence': {'mean': 0.11,\n",
       "      'standardDeviation': 0.36,\n",
       "      'meanAbsoluteDeviation': 0.21,\n",
       "      'total': 8},\n",
       "     'laymanLanguageWordsPerSentence': {'mean': 0.01,\n",
       "      'standardDeviation': 0.12,\n",
       "      'meanAbsoluteDeviation': 0.02,\n",
       "      'total': 1},\n",
       "     'legalLanguageWordsPerSentence': {'mean': 0.01,\n",
       "      'standardDeviation': 0.12,\n",
       "      'meanAbsoluteDeviation': 0.02,\n",
       "      'total': 1},\n",
       "     'militaryLanguageWordsPerSentence': {'mean': 0.04,\n",
       "      'standardDeviation': 0.2,\n",
       "      'meanAbsoluteDeviation': 0.08,\n",
       "      'total': 3},\n",
       "     'politicalLanguageWordsPerSentence': {'mean': 0.32,\n",
       "      'standardDeviation': 0.6,\n",
       "      'meanAbsoluteDeviation': 0.49,\n",
       "      'total': 22},\n",
       "     'socialMediaLanguageWordsPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'colonsPerSentence': {'mean': 0.07,\n",
       "      'standardDeviation': 0.26,\n",
       "      'meanAbsoluteDeviation': 0.13,\n",
       "      'total': 5},\n",
       "     'commasPerSentence': {'mean': 1.17,\n",
       "      'standardDeviation': 1.03,\n",
       "      'meanAbsoluteDeviation': 0.8,\n",
       "      'total': 79},\n",
       "     'dotsPerSentence': {'mean': 1,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 67},\n",
       "     'doubleQuotationMarksPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'exclamationMarksPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'exclamationMarkQuestionMarkSequencesPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'multipleDotsPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'multipleExclamationMarksPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'multipleQuestionMarksPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'questionMarksPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'semicolonsPerSentence': {'mean': 0.07,\n",
       "      'standardDeviation': 0.26,\n",
       "      'meanAbsoluteDeviation': 0.13,\n",
       "      'total': 5},\n",
       "     'singleQuotationMarksPerSentence': {'mean': 0.1,\n",
       "      'standardDeviation': 0.3,\n",
       "      'meanAbsoluteDeviation': 0.18,\n",
       "      'total': 7},\n",
       "     'commonlyMisspelledWordsPerSentence': {'mean': 0,\n",
       "      'standardDeviation': 0,\n",
       "      'meanAbsoluteDeviation': 0,\n",
       "      'total': 0},\n",
       "     'functionWordsPerSentence': {'mean': 14.19,\n",
       "      'standardDeviation': 7.04,\n",
       "      'meanAbsoluteDeviation': 5.78,\n",
       "      'total': 951},\n",
       "     'mostCommonWordsPerSentence': {'mean': 16.16,\n",
       "      'standardDeviation': 8.14,\n",
       "      'meanAbsoluteDeviation': 6.65,\n",
       "      'total': 1083}}}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeprint_test = make_one_writeprint(presidential_speeches.text[0])\n",
    "writeprint_test.extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_indexes_names(one_wp_obj):\n",
    "    index_names=[]\n",
    "    indexes=[]\n",
    "    for readabilityIndex in one_wp_obj.extra_data[\"JSON-LD\"][\"@graph\"][0]['readabilityIndexes']:\n",
    "        index_names.append(readabilityIndex['name'].replace(\" \", \"\").replace(\"-\",\"\"))\n",
    "        indexes.append(readabilityIndex['value'])\n",
    "    for structureIndex in one_wp_obj.extra_data[\"JSON-LD\"][\"@graph\"][0]['structureIndexes']:\n",
    "        try:\n",
    "            indexes.append(one_wp_obj.extra_data[\"JSON-LD\"][\"@graph\"][0]['structureIndexes'][structureIndex]['mean'])\n",
    "            index_names.append(structureIndex)\n",
    "        \n",
    "        except KeyError:\n",
    "                           pass\n",
    "        \n",
    "    return indexes, index_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wp_values(old_table):\n",
    "    new_table=[]\n",
    "    for _ in tqdm(range(len(old_table))):\n",
    "        text, author = old_table.iloc[_]\n",
    "        try:\n",
    "            one_wp = make_one_writeprint(text)\n",
    "        except:\n",
    "            print(_)\n",
    "            continue\n",
    "        indexes, index_names =extract_indexes_names(one_wp)\n",
    "        new_row = [text, author] + indexes\n",
    "        new_table.append(new_row)\n",
    "    columns=list(old_table. columns) + index_names\n",
    "    new_df=pd.DataFrame(new_table, columns=columns)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:24<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "speeches_with_wp=add_wp_values(presidential_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>ColemanLiau</th>\n",
       "      <th>Gulpease</th>\n",
       "      <th>AutomatedReadabilityIndex</th>\n",
       "      <th>tokenLengthPerSentence</th>\n",
       "      <th>charactersPerSentence</th>\n",
       "      <th>atomsPerSentence</th>\n",
       "      <th>tokensPerSentence</th>\n",
       "      <th>phrasesPerSentence</th>\n",
       "      <th>...</th>\n",
       "      <th>exclamationMarkQuestionMarkSequencesPerSentence</th>\n",
       "      <th>multipleDotsPerSentence</th>\n",
       "      <th>multipleExclamationMarksPerSentence</th>\n",
       "      <th>multipleQuestionMarksPerSentence</th>\n",
       "      <th>questionMarksPerSentence</th>\n",
       "      <th>semicolonsPerSentence</th>\n",
       "      <th>singleQuotationMarksPerSentence</th>\n",
       "      <th>commonlyMisspelledWordsPerSentence</th>\n",
       "      <th>functionWordsPerSentence</th>\n",
       "      <th>mostCommonWordsPerSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the last century, both our nations put in p...</td>\n",
       "      <td>obama</td>\n",
       "      <td>9.68</td>\n",
       "      <td>55.75</td>\n",
       "      <td>12.15</td>\n",
       "      <td>4.37</td>\n",
       "      <td>136.47</td>\n",
       "      <td>26.92</td>\n",
       "      <td>25.50</td>\n",
       "      <td>15.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>14.19</td>\n",
       "      <td>16.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Giving all praise and honor to God. The Bible ...</td>\n",
       "      <td>obama</td>\n",
       "      <td>8.22</td>\n",
       "      <td>63.68</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.08</td>\n",
       "      <td>87.05</td>\n",
       "      <td>18.25</td>\n",
       "      <td>17.34</td>\n",
       "      <td>10.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just a guess. But there should be other ways p...</td>\n",
       "      <td>obama</td>\n",
       "      <td>7.89</td>\n",
       "      <td>62.56</td>\n",
       "      <td>7.85</td>\n",
       "      <td>4.27</td>\n",
       "      <td>95.34</td>\n",
       "      <td>20.23</td>\n",
       "      <td>18.37</td>\n",
       "      <td>11.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>9.38</td>\n",
       "      <td>11.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "      <td>obama</td>\n",
       "      <td>8.65</td>\n",
       "      <td>62.79</td>\n",
       "      <td>7.74</td>\n",
       "      <td>4.42</td>\n",
       "      <td>88.56</td>\n",
       "      <td>17.91</td>\n",
       "      <td>16.55</td>\n",
       "      <td>10.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>8.79</td>\n",
       "      <td>10.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well Jessica, look, I'll just give you an exam...</td>\n",
       "      <td>obama</td>\n",
       "      <td>7.23</td>\n",
       "      <td>61.80</td>\n",
       "      <td>8.52</td>\n",
       "      <td>4.10</td>\n",
       "      <td>107.25</td>\n",
       "      <td>23.49</td>\n",
       "      <td>21.34</td>\n",
       "      <td>13.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>12.23</td>\n",
       "      <td>13.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text author  ColemanLiau  \\\n",
       "0  In the last century, both our nations put in p...  obama         9.68   \n",
       "1  Giving all praise and honor to God. The Bible ...  obama         8.22   \n",
       "2  Just a guess. But there should be other ways p...  obama         7.89   \n",
       "3  Mr. Speaker, Mr. Vice President, members of Co...  obama         8.65   \n",
       "4  Well Jessica, look, I'll just give you an exam...  obama         7.23   \n",
       "\n",
       "   Gulpease  AutomatedReadabilityIndex  tokenLengthPerSentence  \\\n",
       "0     55.75                      12.15                    4.37   \n",
       "1     63.68                       7.33                    4.08   \n",
       "2     62.56                       7.85                    4.27   \n",
       "3     62.79                       7.74                    4.42   \n",
       "4     61.80                       8.52                    4.10   \n",
       "\n",
       "   charactersPerSentence  atomsPerSentence  tokensPerSentence  \\\n",
       "0                 136.47             26.92              25.50   \n",
       "1                  87.05             18.25              17.34   \n",
       "2                  95.34             20.23              18.37   \n",
       "3                  88.56             17.91              16.55   \n",
       "4                 107.25             23.49              21.34   \n",
       "\n",
       "   phrasesPerSentence  ...  exclamationMarkQuestionMarkSequencesPerSentence  \\\n",
       "0               15.73  ...                                                0   \n",
       "1               10.80  ...                                                0   \n",
       "2               11.33  ...                                                0   \n",
       "3               10.53  ...                                                0   \n",
       "4               13.67  ...                                                0   \n",
       "\n",
       "   multipleDotsPerSentence  multipleExclamationMarksPerSentence  \\\n",
       "0                      0.0                                    0   \n",
       "1                      0.0                                    0   \n",
       "2                      0.0                                    0   \n",
       "3                      0.0                                    0   \n",
       "4                      0.0                                    0   \n",
       "\n",
       "   multipleQuestionMarksPerSentence  questionMarksPerSentence  \\\n",
       "0                                 0                      0.00   \n",
       "1                                 0                      0.00   \n",
       "2                                 0                      0.02   \n",
       "3                                 0                      0.05   \n",
       "4                                 0                      0.05   \n",
       "\n",
       "   semicolonsPerSentence  singleQuotationMarksPerSentence  \\\n",
       "0                   0.07                             0.10   \n",
       "1                   0.14                             0.23   \n",
       "2                   0.03                             0.59   \n",
       "3                   0.01                             0.29   \n",
       "4                   0.02                             0.76   \n",
       "\n",
       "   commonlyMisspelledWordsPerSentence  functionWordsPerSentence  \\\n",
       "0                                   0                     14.19   \n",
       "1                                   0                      8.20   \n",
       "2                                   0                      9.38   \n",
       "3                                   0                      8.79   \n",
       "4                                   0                     12.23   \n",
       "\n",
       "   mostCommonWordsPerSentence  \n",
       "0                       16.16  \n",
       "1                        9.91  \n",
       "2                       11.46  \n",
       "3                       10.69  \n",
       "4                       13.94  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_with_wp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_labels(df_with_wp_indexes):\n",
    "    features=df_with_wp_indexes.loc[:,\"ColemanLiau\":].values \n",
    "    labels=df_with_wp_indexes.loc[:, \"author\"].values\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y= extract_features_labels(speeches_with_wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.68 55.75 12.15 ...  0.   14.19 16.16]\n",
      " [ 8.22 63.68  7.33 ...  0.    8.2   9.91]\n",
      " [ 7.89 62.56  7.85 ...  0.    9.38 11.46]\n",
      " ...\n",
      " [ 6.68 70.    4.94 ...  0.    7.38  8.38]\n",
      " [ 6.21 68.27  5.28 ...  0.    8.82 10.26]\n",
      " [11.04 54.   12.67 ...  0.   11.32 13.42]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama'\n",
      " 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama'\n",
      " 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama'\n",
      " 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama'\n",
      " 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama'\n",
      " 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'obama'\n",
      " 'obama' 'obama' 'obama' 'obama' 'obama' 'obama' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump' 'trump'\n",
      " 'trump' 'trump' 'trump']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC`\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niharikaghali/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(test_string, classifier):\n",
    "    print(classifier.predict([extract_indexes_names(make_one_writeprint(test_string))[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obama']\n"
     ]
    }
   ],
   "source": [
    "test_string_obama=\"\"\"\n",
    "\n",
    "Tomorrow, at this defining moment in history, you can give this country the change that we need. It starts here in Virginia. It starts here in Manassas. This is where change begins.\n",
    "\n",
    "Our campaign has not been perfect. There are times when I look back and I've said, \"you know I wouldn't have done that if I had thought about it a little bit more.\" But I'll tell you what. When you think about this campaign we've got a lot to be proud of when it comes to the tone that we have set.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "test_classifier(test_string_obama, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trump']\n"
     ]
    }
   ],
   "source": [
    "test_string_trump=\"\"\"\n",
    "\n",
    "But it used to be that they’d argue with me, I’d fight. So I’d fight, they’d fight. I’d fight, they’d fight. Boop-boop. You’d believe me, you’d believe them. Somebody comes out. They had their point of view, I had my point of view. But you’d have an argument. Now what they do is they go silent. It’s called suppression. And that’s what happens in a communist country. That’s what they do. They suppress. You don’t fight with them anymore, unless it’s a bad. They have a little bad story about me, they’ll make it 10 times worse and it’s a major headline. But Hunter Biden, they don’t talk about him. What happened to Hunter? Where’s Hunter? Where is Hunter? They don’t talk about him.\n",
    "\"\"\"\n",
    "test_classifier(test_string_trump, classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
